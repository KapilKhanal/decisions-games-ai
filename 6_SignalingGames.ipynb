{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Signaling Games\n",
    "=======\n",
    "\n",
    "Shane Steinert-Threlkeld  \n",
    "https://www.shane.st  \n",
    "S.N.M.Steinert-Threlkeld AT uva DOT nl  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".rendered_html tbody tr td:first-child {\n",
       "    border-right: 1px solid black;\n",
       "}\n",
       "    \n",
       ".rendered_html table {\n",
       "    font-size: 28px;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style type=\"text/css\">\n",
    ".rendered_html tbody tr td:first-child {\n",
    "    border-right: 1px solid black;\n",
    "}\n",
    "    \n",
    ".rendered_html table {\n",
    "    font-size: 28px;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Last Time\n",
    "-----\n",
    "\n",
    "Low rationality game theory:\n",
    "* Evolution:\n",
    "    - stable strategies, replicator dynamics\n",
    "* Learning:\n",
    "    - reinforcement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Today\n",
    "------\n",
    "\n",
    "_Signaling games_: simple models for the emergence of communication\n",
    "* evolution\n",
    "* reinforcement\n",
    "\n",
    "Afterwards: overview of the course final project, replicating a recent deep RL approach to signaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A Deep Philosophical Issue\n",
    "-------\n",
    "\n",
    "Can language be a _convention_?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Quine: NO! Language is required to establish conventions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Lewis: yes. Language can arise via coordination on Nash equilibria in _signaling games_.\n",
    "\n",
    "    - for him: coordination via salience; later: evolution and learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A Motivating Story\n",
    "------\n",
    "\n",
    "![](imgs/Paul_Revere_Ride.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Simplest Signaling Game\n",
    "------\n",
    "\n",
    "It is an example of a _Bayesian game_, i.e. it has random moves by a \"third player\" that we call \"Nature\".\n",
    "\n",
    "The Sender has private information that it needs to communicate to a Receiver, who can act in the world, and with whom she shares common interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Simplest Signaling Game\n",
    "------\n",
    "\n",
    "1. Nature chooses one of the possible states $s \\in S$ of the world, and informs Sender what state obtains.\n",
    "2. The Sender chooses one of its messages $m \\in M$ and sends it to the Receiver.\n",
    "3. The Receiver sees $m$ (but _not_ $s$), and chooses an action $a \\in A$.\n",
    "4. Both players \"win\" if the Receiver chooses the \"right\" action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "| &#160; | $a_1$ | $a_2$ |\n",
    "| ----- | ----- | ----- |\n",
    "| $s_1$ | 1, 1 | 0, 0 |\n",
    "| $s_2$ | 0, 0 | 1, 1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2x2 Signaling Game in Extensive Form\n",
    "------\n",
    "\n",
    "![](imgs/signaling_extensive.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2x2 Signaling Game in Normal Form\n",
    "-----\n",
    "\n",
    "![](imgs/signaling_normal.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Nash Equilibria\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $(\\sigma_1, \\rho_1)$\n",
    "* $(\\sigma_2, \\rho_2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* All combinations of $\\sigma_3, \\sigma_4$ and $\\rho_3, \\rho_4$: these are called \"pooling\" or \"babbling\" equilibria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "General Case: Three Types of Nash\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](imgs/signaling_pooling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](imgs/signaling_partialpool.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](imgs/signaling_signaling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "ESS in Signaling Games\n",
    "-----\n",
    "\n",
    "To apply the concept of ESS, we have to _symmetrize_ the game.  Now strategies are _pairs_ $(\\sigma, \\rho)$ of a sender and receiver strategy.  Assuming agents are paired uniformly at random, in each role half the time, we have:\n",
    "\n",
    "$$u((\\sigma, \\rho), (\\sigma', \\rho')) = \\frac{1}{2}(u(\\sigma, \\rho') + u(\\sigma', \\rho))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the basic game: only the _signaling systems_ (which are the strict Nash equilibria) are ESS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Theorem (Warneryd 1993).** $(\\sigma, \\rho)$ is an ESS if and only if it is a signaling system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Replicator Dynamic\n",
    "-----\n",
    "\n",
    "**Theorem (Huttegger 2007).** In the 2x2 signaling game, the replicator dynamic converges to a signaling system (modulo a set of measure 0).\n",
    "\n",
    "**Theorem (Huttegger 2007, Pawlowitsch 2008).** When $n > 2$, the replicator dynamic can converge to partial pooling equilibria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Reinforcement Learning\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def belief_to_prob(beliefs, temp=None):\n",
    "    # if temp is specified, do a soft-max\n",
    "    if temp:\n",
    "        beliefs = np.exp(beliefs / temp)\n",
    "    return beliefs / np.sum(beliefs)\n",
    "\n",
    "def choose(beliefs, temp=None):\n",
    "    return np.random.choice(range(len(beliefs)), p=belief_to_prob(beliefs, temp=temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "N = 2\n",
    "# number of states and actions\n",
    "sender = np.ones((N, N))  # rows = states, cols = messages\n",
    "receiver = np.ones((N, N))  # rows = messages, cols = actions\n",
    "\n",
    "utility = np.eye(N)\n",
    "\n",
    "for _ in range(2000):\n",
    "    state = np.random.randint(N)  # get state\n",
    "    message = choose(sender[state])  # get message\n",
    "    action = choose(receiver[message])  # get act\n",
    "    reward = utility[action, state]  # get reward\n",
    "    sender[state, message] += reward  # reinforce sender\n",
    "    receiver[message, action] += reward  # reinforce receiver\n",
    "    \n",
    "print(sender)\n",
    "print(receiver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Reinforcement Learning\n",
    "-----\n",
    "\n",
    "This simple form of RL (sometimes called Roth-Erev) _provably converges_ to one of the two signaling systems, and to each one with probability 0.5.\n",
    "\n",
    "This guarantee does not hold once $N > 2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Richer Settings for Signaling\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* More senders, more receivers, more states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](imgs/signaling_partialcommon.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](imgs/Zollman2005.png)\n",
    "\n",
    "Zollman 2005, \"Talking to Neighbors\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](imgs/voronoi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](imgs/OConnor2014.png)\n",
    "\n",
    "O'Connor 2014, \"The Evolution of Vagueness\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/liVFy7ZO4OA?start=57\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
    "\n",
    "<p>Mordatch and Abbeel 2018, \"Emergence of Grounded Compositional Language in Multi-Agent Populations\"</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Wrapping Up\n",
    "-------\n",
    "\n",
    "Signaling games provide tractable models to explore the emergence of communication.\n",
    "\n",
    "In simple cases, we can prove results about the resulting systems.\n",
    "\n",
    "There is increased interest in AI in learning dynamics of signaling games in richer environments (see, e.g. the [2017](https://sites.google.com/site/emecom2017/) and [2018](https://sites.google.com/site/emecom2018/home?authuser=0) Emergent Communication Workshops at NeurIPS).\n",
    "\n",
    "You'll get some hands-on experience with this kind of work in your final project!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
