{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Game Theory II: Extensive Form\n",
    "=======\n",
    "\n",
    "Shane Steinert-Threlkeld  \n",
    "https://www.shane.st  \n",
    "S.N.M.Steinert-Threlkeld AT uva DOT nl  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Last Time\n",
    "----\n",
    "\n",
    "* Games in _normal form_: simultaneous action of multiple agents\n",
    "* Solution concepts: Pareto optimality, Iterated Removal of Dominante Strategies, Nash equilibria\n",
    "    - tension between individual and collective rationality\n",
    "* Searching for NE is hard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sequential Games\n",
    "--------\n",
    "\n",
    "![AlphaGo Nature paper](imgs/AlphaGo_cover.jpg)\n",
    "\n",
    "credit: Nature Publishing Group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Imperfect Information\n",
    "-------\n",
    "\n",
    "![Phil Ivey](imgs/philivey.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "An Example Game\n",
    "------\n",
    "\n",
    "> A brother and sister can share two cookies.  First, the sister suggests a division of the cookies; the brother accepts (in which case they get the suggested outcome) or rejects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Sharing Game](imgs/SLB_5.1.png)\n",
    "\n",
    "Source: Shoham and Leyton-Brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Extensive Form, Defined\n",
    "------\n",
    "\n",
    "An _extensive form game of perfect information_ is a tuple $\\langle N, A, H, Z, \\chi, \\rho, \\sigma, \\{ u_i \\} \\rangle$: \n",
    "\n",
    "* $N$: set of $n$ players\n",
    "* $A$: a _single_ set of actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* $H$: non-terminal, aka _choice_ nodes\n",
    "* $Z$: terminal (aka final) nodes  \n",
    "    Note: $Z \\cap H = \\emptyset$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* $\\chi : H \\to \\mathcal{P}(A)$: action function  \n",
    "    Assigns to each choice node the set of _available actions_ at that node.  \n",
    "    \n",
    "* $\\rho : H \\to N$: player function  \n",
    "    Assigns to each choice node the player who gets to choose (i.e. whose \"turn\" it is) at that node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* $\\sigma : H \\times A \\to H \\cup Z$: the successor function, i.e. what provides the tree structure\n",
    "\n",
    "    (To enforce tree: if $\\sigma(h_1 , a_1) = \\sigma(h_2 , a_2)$, then $h_1 = h_2$ and $a_1 = a_2$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* $u_i : Z \\to \\mathbb{R}$: agent $i$'s utility function\n",
    "\n",
    "    Note: assigns utility only to _terminal_ nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Strategies and Equilibria\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $S_i := \\prod_{h \\in H : \\rho(h) = i} \\chi(h)$\n",
    "\n",
    "    In other words: player $i$'s _pure_ strategies specify one chosen action (element from $\\chi(h)$) at each of that player's choice nodes (those where $\\rho(h) = i$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Best Response and Nash Equilibrium: exactly as in the normal form case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Converting to Normal Form\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](imgs/SLB_5.2.png)\n",
    "\n",
    "Source: Shoham and Leyton-Brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](imgs/SLB_5.3.png)\n",
    "\n",
    "Source: Shoham and Leyton-Brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](imgs/SLB_5.4.png)\n",
    "\n",
    "Source: Shoham and Leyton-Brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pure Strategy NE\n",
    "------\n",
    "\n",
    "**Theorem.** Every finite extensive-form game of perfect information has a _pure strategy_ Nash equilibrium."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Recall from last lecture: normal form games in general are only guaranteed to have a Nash equilibrium in _mixed_ strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Extensive vs. Normal Form\n",
    "-------\n",
    "\n",
    "So: is the extensive form just a graphically nicer way of looking at a normal form game?  Yes and no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Much more compact representation (exponentially so)\n",
    "* _Novel solution concepts_ that exploit the temporal structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A Non-Credible Threat?\n",
    "------\n",
    "\n",
    "![](imgs/SLB_5.5.png)\n",
    "\n",
    "Source: Shoham and Leyton-Brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Subgame Perfect Equilibrium\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Subgame of $G$ rooted at $h$: restrict $G$ to only $h$ and its descendants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $s$ is a _subgame perfect equilibrium_: for any subgame $G'$ of $G$, $s$ restricted to $G'$ is a Nash equilibrium of $G'$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* $\\{ (B, H), (C, E) \\}$ is _not_ subgame perfect, since $H$ is a not a N.E. of the game restricted to $1$'s last choice node.  \n",
    "    This captures the sense in which the threat is not credible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Backward Induction\n",
    "-----\n",
    "\n",
    "Intuitively:\n",
    "* start at terminal nodes\n",
    "* traverse \"up\" the tree, assigning the maximum attainable utility at each node\n",
    "* lifts utility from terminal to all nodes\n",
    "* equilibrium: at each choice node, take an action with highest utility!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Backward Induction: pseudo-code\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def backward_induction(game, node):\n",
    "    # base case of recursion: terminal nodes\n",
    "    if node in game.terminal:\n",
    "        return game.utility(node)\n",
    "    # assign utility for each agent to the node\n",
    "    best_util = [-np.inf]*game.num_players\n",
    "    for action in game.actions(node):\n",
    "        util_of_action = backward_induction(game.successor(node, action))\n",
    "        # assign utility that's best for the choosing player\n",
    "        if util_of_action[game.player(node)] > best_util(game.player(node)):\n",
    "            best_util = util_of_action\n",
    "    return best_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Backward Induction\n",
    "-----\n",
    "\n",
    "The strategy computed by backward induction (i.e. agents choose an action which maximizes the utilities computed by BI) will always be _subgame perfect_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Backward Induction: Problems, I\n",
    "-------\n",
    "\n",
    "![AlphaGo Nature paper](imgs/AlphaGo_cover.jpg)\n",
    "\n",
    "Source: Nature Publishing Group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In principle, Backward Induction actually can solve Go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Unfortunately: the corresponding game tree has more nodes than there are atoms in the universe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "AlphaGo's insight: use neural networks, trained by reinforcement learning, to prune the tree, only visiting nodes that are likely to have high utility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Backward Induction: Problems, II\n",
    "-------\n",
    "\n",
    "![](imgs/SLB_5.9.png)\n",
    "\n",
    "Source: Shoham and Leyton-Brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Imperfect Information\n",
    "-------\n",
    "\n",
    "![Phil Ivey](imgs/philivey.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "An Example Game\n",
    "-----\n",
    "\n",
    "![](imgs/SLB_5.10.png)\n",
    "\n",
    "Source: Shoham and Leyton-Brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Definition of Imperfect Information\n",
    "----------\n",
    "\n",
    "An extensive game of _imperfect information_ is a game of perfect information together with\n",
    "* for each agent, an _equivalence relation_ $I_i$ on $\\{ h : \\rho(h) = 1 \\}$, such that:  \n",
    "    $$h_1 I_i h_2 \\Rightarrow \\chi(h_1) = \\chi(h_2)$$\n",
    "    $h_1 I_i h_2$, intuitively: player $i$ cannot distinguish between being at node $h_1$ and $h_2$  \n",
    "    A dashed line between $h_1$ and $h_2$ indicates that $h_1 I_i h_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Strategies and Equilibria\n",
    "-----\n",
    "\n",
    "* Pure strategies: instead of choosing at action at each choice node, specify an action at each _equivalence class_ (a.k.a. information set)\n",
    "* Writing $[ h ]_i := \\{ h' : h I_i h' \\}$ and $H_i := \\{ [ h ]_i : \\rho(h) = i \\}$:\n",
    "    $$S_i := \\prod_{H_i} \\chi(H_i)$$\n",
    "    where $\\chi(H_i)$ is well-defined thanks to the condition that indistinguishable nodes have the same action set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Another Example of Imperfect Information\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "TODO: get tikzpicture in notebook; copy tree from Stockholm slides of MAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
